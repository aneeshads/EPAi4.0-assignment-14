{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "### Project",
   "metadata": {
    "cell_id": "00000-680c3c7b-117e-43d7-968e-7df134cb5f3d",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "For this project you have 4 files containing information about persons.\n\nThe files are:\n* `personal_info.csv` -   personal information such as name, gender, etc. (one row per person)\n* `vehicles.csv` -   what vehicle people own (one row per person)\n* `employment.csv` -   where a person is employed (one row per person)\n* `update_status.csv` -   when the person's data was created and last updated\n\nEach file contains a key, `SSN`, which **uniquely** identifies a person.\n\nThis key is present in **all** four files.\n\nYou are guaranteed that the same SSN value is present in **every** file, and that it only appears **once per file**.\n\nIn addition, the files are all sorted by SSN, i.e. the SSN values appear in the same order in each file.",
   "metadata": {
    "cell_id": "00001-4d8d4fd7-c054-4c0e-9105-78e8d31d1dc4",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "##### Goal 1\n\nYour first task is to create iterators for each of the four files that contained cleaned up data, of the correct type (e.g. string, int, date, etc), and represented by a named tuple.\n\nFor now these four iterators are just separate, independent iterators.",
   "metadata": {
    "cell_id": "00002-2ea1a651-d24a-410a-a0c2-efca60a76808",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "7f2ab1ce-231f-4d15-bf2d-40ad69c6591a",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "37188139",
    "execution_start": 1642588859734,
    "execution_millis": 1,
    "deepnote_cell_type": "code"
   },
   "source": "import csv\nfrom itertools import islice\nfrom collections import namedtuple\n\nfile_named_tuple = {'personal_info.csv': 'PersonalInfo', 'employment.csv': 'Employment', 'vehicles.csv': 'Vehicles', 'update_status.csv': 'UpdateStatus'}\n\npersonal_info_data_type = ['INT', 'STRING', 'STRING', 'STRING','STRING']\nvehicle_info_data_type = ['INT', 'STRING', 'STRING', 'INT']\nemployment_info_data_type = ['STRING', 'STRING', 'INT', 'INT']\nupdate_info_data_type = ['INT', 'DATE', 'DATE']\n\ndef get_datatype(filename):\n    if filename == 'personal_info.csv':\n        return personal_info_data_type\n    elif filename == 'employment.csv':\n        return employment_info_data_type\n    elif filename == 'vehicles.csv':\n        return vehicle_info_data_type\n    elif filename == 'update_status.csv':\n        return update_info_data_type\n\n\ndef cast(data_type, value):\n  \"\"\"The function cast has been written to convert the appropriate types to each \\\n  field of data present within the file. The Issue Date has been converted to a list, \\\n  which will be further converted to a namedtuple; Summons Number and Violation code \\\n  values have been converted to type integer.Plate ID, Registration State, Plate Type, \\\n  Vehicle Body type, Vehicle Make and Violation Description have been converted to string \\\n  type of data.\n  \"\"\"\n\n  if data_type == 'DATE':\n      Date = namedtuple('Date', 'Year Month Day')\n      date  = [int(i) for i in value[:10].split('-')]\n      date = Date(*date)\n      return date\n  elif data_type == 'INT':\n    return int(value.replace(\"-\", \"\"))\n  else:\n    return str(value)\n\n\ndef cast_row(data_types, data_row):\n  \"\"\"This function cast_row has been written to convert the input data, which are \\\n  all of string type, to the type corresponding to what has been assigned to them \\\n  within the previous function.\n  \"\"\"\n  return [cast(data_type, value)\n          for data_type, value in zip(data_types, data_row)]\n\n\ndef read_file(file_name):\n    with open(file_name) as f:\n        file_iter = csv.reader(f, delimiter=',', quotechar='\"')\n        header = next(file_iter)\n        NamedTuple_name = namedtuple(file_named_tuple[file_name], header)\n        for row in file_iter:\n            data = cast_row(get_datatype(file_name), row)\n            namedtuple_row = NamedTuple_name(*data)\n            yield namedtuple_row\n",
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "9d259306-75ec-4c85-a117-c61a12d191fc",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "d355d2ce",
    "execution_start": 1642588859735,
    "execution_millis": 2,
    "deepnote_cell_type": "code"
   },
   "source": "# Read the personal info file\nrows = read_file('personal_info.csv')\nfor row in islice(rows, 5):\n    print(row)",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "text": "PersonalInfo(ssn=100539824, first_name='Sebastiano', last_name='Tester', gender='Male', language='Icelandic')\nPersonalInfo(ssn=101714702, first_name='Cayla', last_name='MacDonagh', gender='Female', language='Lao')\nPersonalInfo(ssn=101840356, first_name='Nomi', last_name='Lipprose', gender='Female', language='Yiddish')\nPersonalInfo(ssn=104220928, first_name='Justinian', last_name='Kunzelmann', gender='Male', language='Dhivehi')\nPersonalInfo(ssn=104847144, first_name='Claudianus', last_name='Brixey', gender='Male', language='Afrikaans')\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "420f0237-f1e3-4d45-a21d-d17446a27c3b",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "bd0924b7",
    "execution_start": 1642588859763,
    "execution_millis": 7,
    "deepnote_cell_type": "code"
   },
   "source": "# Read the vehicle info file\nrows = read_file('vehicles.csv')\nfor row in islice(rows, 5):\n    print(row)",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "text": "Vehicles(ssn=100539824, vehicle_make='Oldsmobile', vehicle_model='Bravada', model_year=1993)\nVehicles(ssn=101714702, vehicle_make='Ford', vehicle_model='Mustang', model_year=1997)\nVehicles(ssn=101840356, vehicle_make='GMC', vehicle_model='Yukon', model_year=2005)\nVehicles(ssn=104220928, vehicle_make='Oldsmobile', vehicle_model='Intrigue', model_year=2000)\nVehicles(ssn=104847144, vehicle_make='Ford', vehicle_model='Crown Victoria', model_year=2008)\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "61cd9aa4-63d5-407a-b1e5-f6c3c6be76b6",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "9bf37824",
    "execution_start": 1642588859764,
    "execution_millis": 6,
    "deepnote_cell_type": "code"
   },
   "source": "# Read the employment info file\nrows = read_file('employment.csv')\nfor row in islice(rows, 5):\n    print(row)",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "text": "Employment(employer='Stiedemann-Bailey', department='Research and Development', employee_id=290890771, ssn=100539824)\nEmployment(employer='Nicolas and Sons', department='Sales', employee_id=416841359, ssn=101714702)\nEmployment(employer='Connelly Group', department='Research and Development', employee_id=987952860, ssn=101840356)\nEmployment(employer='Upton LLC', department='Marketing', employee_id=569817552, ssn=104220928)\nEmployment(employer='Zemlak-Olson', department='Business Development', employee_id=462886707, ssn=104847144)\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "26802d71-7a9a-4ceb-ba93-f112efa3ff4c",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "2af8db38",
    "execution_start": 1642588859765,
    "execution_millis": 31,
    "deepnote_cell_type": "code"
   },
   "source": "# Read the status info file\nrows = read_file('update_status.csv')\nfor row in islice(rows, 5):\n    print(row)",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "text": "UpdateStatus(ssn=100539824, last_updated=Date(Year=2017, Month=10, Day=7), created=Date(Year=2016, Month=1, Day=24))\nUpdateStatus(ssn=101714702, last_updated=Date(Year=2017, Month=1, Day=23), created=Date(Year=2016, Month=1, Day=27))\nUpdateStatus(ssn=101840356, last_updated=Date(Year=2017, Month=10, Day=4), created=Date(Year=2016, Month=9, Day=21))\nUpdateStatus(ssn=104220928, last_updated=Date(Year=2017, Month=3, Day=28), created=Date(Year=2016, Month=4, Day=15))\nUpdateStatus(ssn=104847144, last_updated=Date(Year=2018, Month=2, Day=19), created=Date(Year=2016, Month=3, Day=15))\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "##### Goal 2\n\nCreate a single iterable that combines all the columns from all the iterators.\n\nThe iterable should yield named tuples containing all the columns.\nMake sure that the SSN's across the files match!\n\nAll the files are guaranteed to be in SSN sort order, and every SSN is unique, and every SSN appears in every file.\n\nMake sure the SSN is not repeated 4 times - one time per row is enough!",
   "metadata": {
    "cell_id": "00003-0d0dcee0-311e-4534-a82e-9ecaf09ae103",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "6737e02c-3635-4283-9023-70d1c29ec924",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "142d621f",
    "execution_start": 1642588859794,
    "execution_millis": 0,
    "deepnote_cell_type": "code"
   },
   "source": "combined_data_type = ['INT', 'STRING', 'STRING', 'STRING','STRING', 'STRING', 'STRING', 'INT', 'STRING', 'STRING', 'INT', 'DATE', 'DATE']\n\ndef combined_file_row_generator():\n    with open('personal_info.csv') as fpersonal:\n        personal_info_rows = csv.reader(fpersonal, delimiter=',', quotechar='\"')\n        personal_info_header = next(personal_info_rows)\n        with open('vehicles.csv') as fvehicle:\n            vehicle_info_rows = csv.reader(fvehicle, delimiter=',', quotechar='\"')\n            vehicle_info_header  = next(vehicle_info_rows)\n            with open('employment.csv') as femployment:\n                employment_info_rows = csv.reader(femployment, delimiter=',', quotechar='\"')\n                employment_info_header = next(employment_info_rows)\n                with open('update_status.csv') as fupdate:\n                    update_info_rows = csv.reader(fupdate, delimiter=',', quotechar='\"')\n                    update_info_header = next(update_info_rows) \n                    CombinedInfo = namedtuple(\"CombinedInfo\", personal_info_header+vehicle_info_header[1:]+employment_info_header[:-1]+update_info_header[1:])\n                    for personal, vehicle, employment, update in zip(personal_info_rows, vehicle_info_rows, employment_info_rows, update_info_rows):\n                        final_row = personal+vehicle[1:]+employment[:-1]+update[1:]\n                        final_row = cast_row(combined_data_type, final_row)\n                        info_row = CombinedInfo(*final_row)\n                        yield  info_row\n",
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "rows = combined_file_row_generator()\nfor row in islice(rows, 5):\n    print(row) ",
   "metadata": {
    "cell_id": "80bbb518-c606-4621-b0d8-646d5fdb5960",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "35a02284",
    "execution_start": 1642588859795,
    "execution_millis": 38,
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "CombinedInfo(ssn=100539824, first_name='Sebastiano', last_name='Tester', gender='Male', language='Icelandic', vehicle_make='Oldsmobile', vehicle_model='Bravada', model_year=1993, employer='Stiedemann-Bailey', department='Research and Development', employee_id=290890771, last_updated=Date(Year=2017, Month=10, Day=7), created=Date(Year=2016, Month=1, Day=24))\nCombinedInfo(ssn=101714702, first_name='Cayla', last_name='MacDonagh', gender='Female', language='Lao', vehicle_make='Ford', vehicle_model='Mustang', model_year=1997, employer='Nicolas and Sons', department='Sales', employee_id=416841359, last_updated=Date(Year=2017, Month=1, Day=23), created=Date(Year=2016, Month=1, Day=27))\nCombinedInfo(ssn=101840356, first_name='Nomi', last_name='Lipprose', gender='Female', language='Yiddish', vehicle_make='GMC', vehicle_model='Yukon', model_year=2005, employer='Connelly Group', department='Research and Development', employee_id=987952860, last_updated=Date(Year=2017, Month=10, Day=4), created=Date(Year=2016, Month=9, Day=21))\nCombinedInfo(ssn=104220928, first_name='Justinian', last_name='Kunzelmann', gender='Male', language='Dhivehi', vehicle_make='Oldsmobile', vehicle_model='Intrigue', model_year=2000, employer='Upton LLC', department='Marketing', employee_id=569817552, last_updated=Date(Year=2017, Month=3, Day=28), created=Date(Year=2016, Month=4, Day=15))\nCombinedInfo(ssn=104847144, first_name='Claudianus', last_name='Brixey', gender='Male', language='Afrikaans', vehicle_make='Ford', vehicle_model='Crown Victoria', model_year=2008, employer='Zemlak-Olson', department='Business Development', employee_id=462886707, last_updated=Date(Year=2018, Month=2, Day=19), created=Date(Year=2016, Month=3, Day=15))\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "source": "##### Goal 3\n\nNext, you want to identify any stale records, where stale simply means the record has not been updated since 3/1/2017 (e.g. last update date < 3/1/2017). Create an iterator that only contains current records (i.e. not stale) based on the `last_updated` field from the `status_update` file.",
   "metadata": {
    "cell_id": "00004-50dcb66c-e9c5-4483-a5b2-c67070f56e43",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "4607fff1-6171-4595-a261-8aba03553bc8",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "bd8c8381",
    "execution_start": 1642588859832,
    "execution_millis": 0,
    "deepnote_cell_type": "code"
   },
   "source": "def combined_file_row_generator_filter_stale():\n    with open('personal_info.csv') as fpersonal:\n        personal_info_rows = csv.reader(fpersonal, delimiter=',', quotechar='\"')\n        personal_info_header = next(personal_info_rows)\n        with open('vehicles.csv') as fvehicle:\n            vehicle_info_rows = csv.reader(fvehicle, delimiter=',', quotechar='\"')\n            vehicle_info_header  = next(vehicle_info_rows)\n            with open('employment.csv') as femployment:\n                employment_info_rows = csv.reader(femployment, delimiter=',', quotechar='\"')\n                employment_info_header = next(employment_info_rows)\n                with open('update_status.csv') as fupdate:\n                    update_info_rows = csv.reader(fupdate, delimiter=',', quotechar='\"')\n                    update_info_header = next(update_info_rows) \n                    CombinedInfo = namedtuple(\"CombinedInfo\", personal_info_header+vehicle_info_header[1:]+employment_info_header[:-1]+update_info_header[1:])\n                    for personal, vehicle, employment, update in zip(personal_info_rows, vehicle_info_rows, employment_info_rows, update_info_rows):\n                        final_row = personal+vehicle[1:]+employment[:-1]+update[1:]\n                        final_row = cast_row(combined_data_type, final_row)\n                        info_row = CombinedInfo(*final_row)\n                        # if the record was update after 3/1/2017, yield the row, else pass the iteration\n                        if ((info_row.last_updated.Year >= 2017) and (info_row.last_updated.Month >= 3) and (info_row.last_updated.Day >= 1)):\n                            yield  info_row\n                        else:\n                            pass",
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "rows = combined_file_row_generator_filter_stale()\nfor row in islice(rows, 5):\n    print(row)  ",
   "metadata": {
    "cell_id": "1f28a44a-ec50-4d30-8a1c-762e6e697975",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "44187557",
    "execution_start": 1642588859832,
    "execution_millis": 45,
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "CombinedInfo(ssn=100539824, first_name='Sebastiano', last_name='Tester', gender='Male', language='Icelandic', vehicle_make='Oldsmobile', vehicle_model='Bravada', model_year=1993, employer='Stiedemann-Bailey', department='Research and Development', employee_id=290890771, last_updated=Date(Year=2017, Month=10, Day=7), created=Date(Year=2016, Month=1, Day=24))\nCombinedInfo(ssn=101840356, first_name='Nomi', last_name='Lipprose', gender='Female', language='Yiddish', vehicle_make='GMC', vehicle_model='Yukon', model_year=2005, employer='Connelly Group', department='Research and Development', employee_id=987952860, last_updated=Date(Year=2017, Month=10, Day=4), created=Date(Year=2016, Month=9, Day=21))\nCombinedInfo(ssn=104220928, first_name='Justinian', last_name='Kunzelmann', gender='Male', language='Dhivehi', vehicle_make='Oldsmobile', vehicle_model='Intrigue', model_year=2000, employer='Upton LLC', department='Marketing', employee_id=569817552, last_updated=Date(Year=2017, Month=3, Day=28), created=Date(Year=2016, Month=4, Day=15))\nCombinedInfo(ssn=105275541, first_name='Federico', last_name='Aggett', gender='Male', language='Chinese', vehicle_make='Ford', vehicle_model='Mustang', model_year=2001, employer='Kohler, Bradtke and Davis', department='Support', employee_id=800975518, last_updated=Date(Year=2017, Month=7, Day=24), created=Date(Year=2016, Month=7, Day=23))\nCombinedInfo(ssn=105915022, first_name='Moselle', last_name='Apfel', gender='Female', language='Latvian', vehicle_make='Isuzu', vehicle_model='Hombre Space', model_year=2000, employer='Lind-Jast', department='Marketing', employee_id=796418731, last_updated=Date(Year=2018, Month=3, Day=24), created=Date(Year=2016, Month=3, Day=24))\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "source": "##### Goal 4\n\nFind the largest group of car makes for each gender.\n\nPossibly more than one such group per gender exists (equal sizes).",
   "metadata": {
    "cell_id": "00005-c2e653f8-745d-4c95-b8be-ad4eb673e9f8",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "1358c637-c440-40b1-b51f-0cc9b2f2fbc3",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "c477c472",
    "execution_start": 1642588859875,
    "execution_millis": 0,
    "deepnote_cell_type": "code"
   },
   "source": "male_vehicle_dict = {}\nfemale_vehicle_dict = {}\n\ndef car_make_according_to_gender():\n    rows = combined_file_row_generator()\n    for row in rows:\n        if(row.gender == 'Male'):\n            if row.vehicle_make not in male_vehicle_dict:\n                male_vehicle_dict.__setitem__(row.vehicle_make, 1)\n            else:\n                male_vehicle_dict[row.vehicle_make] = male_vehicle_dict[row.vehicle_make] + 1\n        elif(row.gender == 'Female'):\n            if row.vehicle_make not in female_vehicle_dict:\n                female_vehicle_dict.__setitem__(row.vehicle_make, 1)\n            else:\n                female_vehicle_dict[row.vehicle_make] = female_vehicle_dict[row.vehicle_make] + 1\n    male_dict_list = sorted(male_vehicle_dict.items(), key=lambda x:x[1], reverse = True)\n    print(\"Male : \", male_dict_list)\n    female_dict_list = sorted(female_vehicle_dict.items(), key=lambda x:x[1], reverse = True)\n    print(\"Female : \", female_dict_list)\n\n",
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "car_make_according_to_gender()",
   "metadata": {
    "cell_id": "facc102a-a429-4686-adaf-bd58d2aa3827",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "38500a22",
    "execution_start": 1642588859876,
    "execution_millis": 223,
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Male :  [('Ford', 44), ('Chevrolet', 38), ('GMC', 31), ('Mitsubishi', 29), ('Toyota', 26), ('Dodge', 25), ('Mercedes-Benz', 23), ('Volkswagen', 19), ('Buick', 17), ('Audi', 17), ('Mazda', 14), ('Pontiac', 13), ('Mercury', 12), ('BMW', 12), ('Cadillac', 11), ('Acura', 10), ('Volvo', 10), ('Hyundai', 10), ('Honda', 10), ('Infiniti', 9), ('Subaru', 8), ('Lexus', 8), ('Saab', 8), ('Lincoln', 7), ('Jeep', 7), ('Nissan', 7), ('Oldsmobile', 6), ('Kia', 6), ('Jaguar', 5), ('Plymouth', 5), ('Maserati', 5), ('Porsche', 5), ('Suzuki', 5), ('Lotus', 5), ('Aston Martin', 4), ('Lamborghini', 4), ('Isuzu', 3), ('Chrysler', 3), ('Saturn', 3), ('Bentley', 3), ('Land Rover', 3), ('Maybach', 2), ('Panoz', 2), ('Rolls-Royce', 2), ('Geo', 2), ('Scion', 1), ('Jensen', 1), ('Smart', 1), ('Hummer', 1), ('Corbin', 1), ('Daewoo', 1), ('Aptera', 1), ('Eagle', 1), ('Austin', 1)]\nFemale :  [('Ford', 48), ('Chevrolet', 48), ('Mitsubishi', 25), ('Toyota', 24), ('GMC', 23), ('Dodge', 20), ('Mercedes-Benz', 18), ('Lexus', 17), ('Volvo', 15), ('Mazda', 15), ('Audi', 14), ('Pontiac', 14), ('BMW', 13), ('Suzuki', 13), ('Nissan', 12), ('Acura', 11), ('Volkswagen', 11), ('Buick', 11), ('Honda', 10), ('Land Rover', 9), ('Mercury', 9), ('Kia', 9), ('Subaru', 9), ('Infiniti', 9), ('Chrysler', 8), ('Oldsmobile', 8), ('Lotus', 7), ('Cadillac', 6), ('Jeep', 6), ('Porsche', 5), ('Bentley', 5), ('Plymouth', 4), ('Hyundai', 4), ('Lincoln', 4), ('Isuzu', 3), ('Scion', 3), ('Saturn', 3), ('Lamborghini', 3), ('Saab', 3), ('Jaguar', 3), ('Rolls-Royce', 2), ('Aston Martin', 2), ('Bugatti', 1), ('Eagle', 1), ('Geo', 1), ('Smart', 1), ('Morgan', 1), ('Austin', 1), ('Panoz', 1)]\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "source": "#### Hints",
   "metadata": {
    "collapsed": true,
    "cell_id": "00006-2c87dc4f-f8a8-4087-983e-9fc980db5621",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "You will not be able to use a simple split approach here, as I explain in the video.\n\nInstead you should use the `csv` module and the `reader` function.\n\nHere's a simple example of how to use it - you will need to expand on this for your project goals, but this is a good starting point.",
   "metadata": {
    "cell_id": "00007-71f85cb7-61a6-4b05-b811-2f95cab00785",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=720855a5-d2ae-4023-b2ce-6e426650283f' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "deepnote_notebook_id": "8f58b6e2-d138-4ed1-b49f-da90c2adbd3b",
  "deepnote_execution_queue": [],
  "deepnote": {}
 }
}